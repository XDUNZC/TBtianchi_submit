{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "@time: 2019/01/11 11:28\n",
    "spytensor\n",
    "'''\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from IPython import embed\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(41)\n",
    "\n",
    "#0为背景\n",
    "classname_to_id = {\"person\": 1}\n",
    "\n",
    "class Csv2CoCo:\n",
    "\n",
    "    def __init__(self,image_dir,total_annos):\n",
    "        self.images = []\n",
    "        self.annotations = []\n",
    "        self.categories = []\n",
    "        self.img_id = 0\n",
    "        self.ann_id = 0\n",
    "        self.image_dir = image_dir\n",
    "        self.total_annos = total_annos\n",
    "\n",
    "    def save_coco_json(self, instance, save_path):\n",
    "        json.dump(instance, open(save_path, 'w'), ensure_ascii=False, indent=2)  # indent=2 更加美观显示\n",
    "\n",
    "    # 由txt文件构建COCO\n",
    "    def to_coco(self, keys):\n",
    "        self._init_categories()\n",
    "        for key in keys:\n",
    "            self.images.append(self._image(key))\n",
    "            shapes = self.total_annos[key]\n",
    "            for shape in shapes:\n",
    "                bboxi = []\n",
    "                for cor in shape[:-1]:\n",
    "                    bboxi.append(int(cor))\n",
    "                label = shape[-1]\n",
    "                annotation = self._annotation(bboxi,label)\n",
    "                self.annotations.append(annotation)\n",
    "                self.ann_id += 1\n",
    "            self.img_id += 1\n",
    "        instance = {}\n",
    "        instance['info'] = 'spytensor created'\n",
    "        instance['license'] = ['license']\n",
    "        instance['images'] = self.images\n",
    "        instance['annotations'] = self.annotations\n",
    "        instance['categories'] = self.categories\n",
    "        return instance\n",
    "\n",
    "    # 构建类别\n",
    "    def _init_categories(self):\n",
    "        for k, v in classname_to_id.items():\n",
    "            category = {}\n",
    "            category['id'] = v\n",
    "            category['name'] = k\n",
    "            self.categories.append(category)\n",
    "\n",
    "    # 构建COCO的image字段\n",
    "    def _image(self, path):\n",
    "        image = {}\n",
    "        print(path)\n",
    "        img = cv2.imread(self.image_dir + path)\n",
    "        image['height'] = img.shape[0]\n",
    "        image['width'] = img.shape[1]\n",
    "        image['id'] = self.img_id\n",
    "        image['file_name'] = path\n",
    "        return image\n",
    "\n",
    "    # 构建COCO的annotation字段\n",
    "    def _annotation(self, shape,label):\n",
    "        # label = shape[-1]\n",
    "        points = shape[:4]\n",
    "        annotation = {}\n",
    "        annotation['id'] = self.ann_id\n",
    "        annotation['image_id'] = self.img_id\n",
    "        annotation['category_id'] = int(classname_to_id[label])\n",
    "        annotation['segmentation'] = self._get_seg(points)\n",
    "        annotation['bbox'] = self._get_box(points)\n",
    "        annotation['iscrowd'] = 0\n",
    "        annotation['area'] = self._get_area(points)\n",
    "        return annotation\n",
    "\n",
    "    # COCO的格式： [x1,y1,w,h] 对应COCO的bbox格式\n",
    "    def _get_box(self, points):\n",
    "        min_x = points[0]\n",
    "        min_y = points[1]\n",
    "        max_x = points[2]\n",
    "        max_y = points[3]\n",
    "        return [min_x, min_y, max_x - min_x, max_y - min_y]\n",
    "    # 计算面积\n",
    "    def _get_area(self, points):\n",
    "        min_x = points[0]\n",
    "        min_y = points[1]\n",
    "        max_x = points[2]\n",
    "        max_y = points[3]\n",
    "        return (max_x - min_x+1) * (max_y - min_y+1)\n",
    "    # segmentation\n",
    "    def _get_seg(self, points):\n",
    "        min_x = points[0]\n",
    "        min_y = points[1]\n",
    "        max_x = points[2]\n",
    "        max_y = points[3]\n",
    "        h = max_y - min_y\n",
    "        w = max_x - min_x\n",
    "        a = []\n",
    "        a.append([min_x,min_y, min_x,min_y+0.5*h, min_x,max_y, min_x+0.5*w,max_y, max_x,max_y, max_x,max_y-0.5*h, max_x,min_y, max_x-0.5*w,min_y])\n",
    "        return a\n",
    "   \n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2num = {'长马甲': 0, '古装': 1, '短马甲': 2, '背心上衣': 3, '背带裤': 4, '连体衣': 5, '吊带上衣': 6, '中裤': 7, '短袖衬衫': 8, '无袖上衣': 9,\n",
    "                 '长袖衬衫': 10, '中等半身裙': 11, '长半身裙': 12, '长外套': 13, '短裙': 14, '无袖连衣裙': 15, '短裤': 16, '短外套': 17,\n",
    "                 '长袖连衣裙': 18, '长袖上衣': 19, '长裤': 20, '短袖连衣裙': 21, '短袖上衣': 22, '古风': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_csv_image_dataset(data_root_path='data/',mode='train'):\n",
    "    dataset_paths = glob.glob(data_root_path+mode+'*')\n",
    "    # 图像库中标注\n",
    "    img_ann_folder_paths = []  # 所有data/train_dataset_part<n>/image_annotatonl中所有文件夹\n",
    "\n",
    "    # 视频库中标注\n",
    "    video_ann_paths = []  # 所有data/train_dataset_part<n>/video_annotation中所有json文件\n",
    "\n",
    "\n",
    "    for dataset_path in dataset_paths:\n",
    "        img_ann_folder_paths.extend(glob.glob(dataset_path + '/image_annotation/*'))\n",
    "\n",
    "        video_ann_paths.extend(glob.glob(dataset_path + '/video_annotation/*.json'))\n",
    "\n",
    "    image_db = []\n",
    "    for img_ann_folder_path in img_ann_folder_paths[:]:\n",
    "        split_list = img_ann_folder_path.split('/')\n",
    "        img_folder_path = 'data/' + split_list[1] + '/image/' + split_list[-1] + '/'\n",
    "        json_paths = glob.glob(img_ann_folder_path + '/*.json')\n",
    "        for json_path in json_paths:\n",
    "            with open(json_path, 'r') as f:\n",
    "                img_anns = json.load(f)\n",
    "            if len(img_anns['annotations']) > 0:\n",
    "                flag = 0\n",
    "                for img_ann in img_anns['annotations']:\n",
    "                    if img_ann['label'] not in aug_label:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                img_path = img_folder_path + json_path.split('/')[-1].split('.')[0] + '.jpg'\n",
    "                image_db.append([img_path, json_path, -1])\n",
    "                if flag:\n",
    "                    break\n",
    "    image_db = pd.DataFrame(image_db, columns=['file', 'ann', 'frame'])\n",
    "\n",
    "    video_db = []\n",
    "\n",
    "    for json_path in video_ann_paths[:]:\n",
    "        with open(json_path, 'r') as f:  # 'data/train_dataset_part3/video_annotation/002061.json'\n",
    "            v_ann = json.load(f)\n",
    "        split_list = json_path.split('/')\n",
    "        img_folder_path = 'data/' + split_list[1] + '/video/' + split_list[-1].split('.')[0] + '.mp4'\n",
    "        for fram in v_ann['frames']:\n",
    "            if len(fram['annotations']) > 0:\n",
    "                flag = 0\n",
    "                for img_ann in fram['annotations']:\n",
    "                    if img_ann['label'] not in aug_label:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                frame_index = fram['frame_index']\n",
    "                video_db.append([img_folder_path, json_path, frame_index])\n",
    "                if flag:\n",
    "                    break\n",
    "\n",
    "    video_db = pd.DataFrame(video_db, columns=['file', 'ann', 'frame'])\n",
    "    train_db = pd.concat([image_db, video_db])\n",
    "    assert len(train_db) == len(image_db) + len(video_db)\n",
    "    train_db.to_csv(data_root_path+mode+'_down_sample.csv', index=False)\n",
    "    print('已生成csv路径文件：' + data_root_path+mode+'_down_sample.csv')\n",
    "    print(train_db.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"train.csv\"\n",
    "image_dir = \"images/\"\n",
    "saved_coco_path = \"./\"\n",
    "# 整合csv格式标注文件\n",
    "total_csv_annotations = {}\n",
    "annotations = pd.read_csv(csv_file,header=None).values\n",
    "for annotation in annotations:\n",
    "    key = annotation[0].split(os.sep)[-1]\n",
    "    value = np.array([annotation[1:]])\n",
    "    if key in total_csv_annotations.keys():\n",
    "        total_csv_annotations[key] = np.concatenate((total_csv_annotations[key],value),axis=0)\n",
    "    else:\n",
    "        total_csv_annotations[key] = value\n",
    "# 按照键值划分数据\n",
    "total_keys = list(total_csv_annotations.keys())\n",
    "train_keys, val_keys = train_test_split(total_keys, test_size=0.2)\n",
    "print(\"train_n:\", len(train_keys), 'val_n:', len(val_keys))\n",
    "# 创建必须的文件夹\n",
    "if not os.path.exists('%scoco/annotations/'%saved_coco_path):\n",
    "    os.makedirs('%scoco/annotations/'%saved_coco_path)\n",
    "if not os.path.exists('%scoco/images/train2017/'%saved_coco_path):\n",
    "    os.makedirs('%scoco/images/train2017/'%saved_coco_path)\n",
    "if not os.path.exists('%scoco/images/val2017/'%saved_coco_path):\n",
    "    os.makedirs('%scoco/images/val2017/'%saved_coco_path)\n",
    "# 把训练集转化为COCO的json格式\n",
    "l2c_train = Csv2CoCo(image_dir=image_dir,total_annos=total_csv_annotations)\n",
    "train_instance = l2c_train.to_coco(train_keys)\n",
    "l2c_train.save_coco_json(train_instance, '%scoco/annotations/instances_train2017.json'%saved_coco_path)\n",
    "for file in train_keys:\n",
    "    shutil.copy(image_dir+file,\"%scoco/images/train2017/\"%saved_coco_path)\n",
    "for file in val_keys:\n",
    "    shutil.copy(image_dir+file,\"%scoco/images/val2017/\"%saved_coco_path)\n",
    "# 把验证集转化为COCO的json格式\n",
    "l2c_val = Csv2CoCo(image_dir=image_dir,total_annos=total_csv_annotations)\n",
    "val_instance = l2c_val.to_coco(val_keys)\n",
    "l2c_val.save_coco_json(val_instance, '%scoco/annotations/instances_val2017.json'%saved_coco_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
